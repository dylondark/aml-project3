{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ff9408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#AML project 3, by Luke Gegick, Dylan Miller, Jackson Dockerty\n",
    "\n",
    "# The below code is to help parse the data to see the trend the data follows, below this code is the different models\n",
    "# used to predict on this media\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "print(min_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05950950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9573643410852714\n",
      "Test accuracy: 0.937984496124031\n"
     ]
    }
   ],
   "source": [
    "#first version, using Linear Regression\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "partial_eclipse_of_sun = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), len(partial_eclipse_of_sun))\n",
    "if min_count < 50:\n",
    "    min_count = 50\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse_of_sun = partial_eclipse_of_sun.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_annular_eclipse, sample_hybrid_eclipse,\n",
    "                       sample_partial_eclipse, sample_partial_eclipse_of_sun], ignore_index = True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "# set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)), \n",
    "                       ('lr', LogisticRegression())])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'lr__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'lr__penalty': ['l1', 'l2'],  # Regularization penalty\n",
    "    'lr__solver': ['liblinear', 'saga'],  # Solver for optimization problem\n",
    "    'lr__max_iter': [10000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV, cv is the number of folds, verbose tells it not to state what its implementing\n",
    "#and the n_jobs allows the program to utilize all of the cores of the cpu for faster times\n",
    "grid = GridSearchCV(clf2, param_grid, cv=3, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for logistic regression for the given data\n",
    "best_params = grid.best_params_\n",
    "\n",
    "#set the new parameters to the pipeline\n",
    "clf2.set_params(**best_params)\n",
    "\n",
    "#fit the pipeline to the data\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", clf2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf2.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121b6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
