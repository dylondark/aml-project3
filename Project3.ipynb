{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ff9408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#AML project 3, by Luke Gegick, Dylan Miller, Jackson Dockerty\n",
    "\n",
    "# The below code is to help parse the data to see the trend the data follows, below this code is the different models\n",
    "# used to predict on this media\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "print(min_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05950950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9635416666666666\n",
      "Test accuracy: 0.75\n",
      "[[3 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 4 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 2 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "#first version, using Linear Regression\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 20:\n",
    "    min_count = 20\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "# set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('lr', LogisticRegression())])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'lr__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'lr__penalty': ['l1', 'l2'],  # Regularization penalty\n",
    "    'lr__solver': ['liblinear', 'saga'],  # Solver for optimization problem\n",
    "    'lr__max_iter': [10000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV, cv is the number of folds, verbose tells it not to state what its implementing\n",
    "#and the n_jobs allows the program to utilize all of the cores of the cpu for faster times\n",
    "grid = GridSearchCV(clf2, param_grid, cv=3, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for logistic regression for the given data\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# set the new parameters to the pipeline\n",
    "clf2.set_params(**best_params)\n",
    "\n",
    "# fit the pipeline to the data\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted labels and set up confustion matrix\n",
    "y_pred = clf2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# output all relevant accuracies\n",
    "print(\"Train accuracy:\", clf2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf2.score(X_test, y_test)) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b64c3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7604166666666666\n",
      "Test accuracy: 0.6458333333333334\n",
      "[[1 2 0 1 0 0 0 0 0 0 0 0]\n",
      " [2 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 2 1]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Model 2 - Knn Learning Model\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 20:\n",
    "    min_count = 20\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "# set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('knn', KNeighborsClassifier())])\n",
    "# Define parameters for grid search\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': range(3, 20),  # Test K values from 10 to 17\n",
    "    'knn__metric': ['manhattan', 'chebyshev', 'minkowski'],\n",
    "    'knn__weights': ['distance', 'uniform']\n",
    "}\n",
    "\n",
    "# Perform grid search, note cv is the number of folds it tests over\n",
    "grid = GridSearchCV(clf2, param_grid, cv = 5, scoring='accuracy', n_jobs = -1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for KNN from grid search\n",
    "best_params = grid.best_params_\n",
    "best_k = best_params['knn__n_neighbors']\n",
    "\n",
    "# Update the pipeline with the best parameters\n",
    "clf2.set_params(knn__n_neighbors = best_k)\n",
    "\n",
    "# Fit the pipeline with updated parameters\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted labels and set up confustion matrix\n",
    "y_pred = clf2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# output all relevant accuracies\n",
    "print(\"Train accuracy:\", clf2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf2.score(X_test, y_test)) \n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3 - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ebd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 4 - K means (unsupervised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
