{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9f9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code uses mapped values to get and find the predictions\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b866a9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split Accuracy: 0.9445833333333333\n",
      "Test Split Accuracy: 0.925\n",
      "[[36  5  0  1  2  0  0  0  4  1  1  0]\n",
      " [ 0 48  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 35  1  8  1  4  0  1  0]\n",
      " [ 0  0  0  0  0 50  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 50  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  2  0 36  4  3  2]\n",
      " [ 0  0  0  0  0  0  0  0  0 50  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 50  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 50]]\n",
      "\n",
      "Test Accuracy based on True Labels: 85.82%\n"
     ]
    }
   ],
   "source": [
    "# Model 1 KNN - Mapped\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 250:\n",
    "    min_count = 250\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "# set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('knn', KNeighborsClassifier())])\n",
    "# Define parameters for grid search\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': range(3, 20),  # Test K values from 10 to 17\n",
    "    'knn__metric': ['manhattan', 'chebyshev', 'minkowski'],\n",
    "    'knn__weights': ['distance', 'uniform']\n",
    "}\n",
    "\n",
    "# Perform grid search, note cv is the number of folds it tests over\n",
    "grid = GridSearchCV(clf2, param_grid, cv = 4, scoring='accuracy', n_jobs = -1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for KNN from grid search\n",
    "best_params = grid.best_params_\n",
    "best_k = best_params['knn__n_neighbors']\n",
    "\n",
    "# Update the pipeline with the best parameters\n",
    "clf2.set_params(knn__n_neighbors = best_k)\n",
    "\n",
    "# Fit the pipeline with updated parameters\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted labels and set up confustion matrix\n",
    "y_pred = clf2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# output all relevant accuracies\n",
    "print(\"Train Split Accuracy:\", clf2.score(X_train, y_train))\n",
    "print(\"Test Split Accuracy:\", clf2.score(X_test, y_test)) \n",
    "print(cm)\n",
    "\n",
    "## test the data against the testing data ##\n",
    "\n",
    "# read in the testing data\n",
    "test_eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Test_Without_Eclipse_Type.csv\", index_col = \"Catalog Number\")\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "test_eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "test_eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "test_eclipse_df = test_eclipse_df.drop([\"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "test_X = test_eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "# scale the data, then impute the data\n",
    "scaler = StandardScaler()\n",
    "test_X_scaled = scaler.fit_transform(test_X)\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan, fill_value=None)\n",
    "test_X_imputed = imputer.fit_transform(test_X_scaled)\n",
    "\n",
    "# Predict eclipse types for the testing data\n",
    "y_test_pred = clf2.predict(test_X_imputed)\n",
    "\n",
    "# Convert predicted eclipse types to integers and ensure they are within the range [0, 18]\n",
    "y_test_pred = np.clip(y_test_pred, 0, 18)\n",
    "\n",
    "# Read the true eclipse labels for the testing data\n",
    "true_labels_df = pd.read_csv(\"Eclipse_Pred\\True_Eclipse_Test_Label.csv\", index_col=\"Catalog Number\")\n",
    "\n",
    "# Map the predicted Eclipse types\n",
    "mapped_pred = np.where((y_test_pred >= 0) & (y_test_pred <= 5), 0,  # Map 0-5 to 0\n",
    "              np.where((y_test_pred >= 6) & (y_test_pred <= 11), 6,  # Map 6-11 to 6\n",
    "              np.where((y_test_pred >= 12) & (y_test_pred <= 14), 12,  # Map 12-14 to 12\n",
    "              np.where((y_test_pred >= 15) & (y_test_pred <= 18), 15, y_test_pred))))  # Map 15-18 to 15\n",
    "\n",
    "# Calculate test accuracy by comparing mapped predicted and true labels\n",
    "test_accuracy = np.mean(mapped_pred == true_labels_df[\"Eclipse Type\"]) * 100\n",
    "print(\"\\nTest Accuracy based on True Labels: {:.2f}%\".format(test_accuracy))\n",
    "\n",
    "# Write the predicted eclipse types to the DataFrame\n",
    "test_eclipse_df['Pred_Eclipse_Type'] = mapped_pred\n",
    "\n",
    "# Write the predictions to a new file\n",
    "test_eclipse_df.to_csv(\"Project3_pred.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70abae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.94125\n",
      "Test accuracy: 0.9133333333333333\n",
      "[[42  6  0  0  0  0  0  0  0  0  1  1]\n",
      " [ 0 47  0  0  0  0  0  0  0  0  3  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 40  0  7  0  2  0  0  0]\n",
      " [ 0  0  0  0  0 50  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0 47  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 40  5  1  4]\n",
      " [ 0  0  0  0  0  0  0  0  0 50  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0 41  6]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9 41]]\n",
      "\n",
      "Test Accuracy based on True Labels: 55.58%\n"
     ]
    }
   ],
   "source": [
    "# Model 2 Logistic Regression - Mapped\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 250:\n",
    "    min_count = 250\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "# set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('lr', LogisticRegression())])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'lr__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'lr__penalty': ['l1', 'l2'],  # Regularization penalty\n",
    "    'lr__solver': ['liblinear', 'saga'],  # Solver for optimization problem\n",
    "    'lr__max_iter': [10000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV, cv is the number of folds, verbose tells it not to state what its implementing\n",
    "#and the n_jobs allows the program to utilize all of the cores of the cpu for faster times\n",
    "grid = GridSearchCV(clf2, param_grid, cv=3, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for logistic regression for the given data\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# set the new parameters to the pipeline\n",
    "clf2.set_params(**best_params)\n",
    "\n",
    "# fit the pipeline to the data\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted labels and set up confustion matrix\n",
    "y_pred = clf2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# output all relevant accuracies\n",
    "print(\"Train accuracy:\", clf2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf2.score(X_test, y_test)) \n",
    "print(cm)\n",
    "\n",
    "## test the data against the testing data ##\n",
    "\n",
    "# read in the testing data\n",
    "test_eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Test_Without_Eclipse_Type.csv\", index_col = \"Catalog Number\")\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "test_eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "test_eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "test_eclipse_df = test_eclipse_df.drop([\"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "test_X = test_eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "# scale the data, then impute the data\n",
    "scaler = StandardScaler()\n",
    "test_X_scaled = scaler.fit_transform(test_X)\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan, fill_value=None)\n",
    "test_X_imputed = imputer.fit_transform(test_X_scaled)\n",
    "\n",
    "# Predict eclipse types for the testing data\n",
    "y_test_pred = clf2.predict(test_X_imputed)\n",
    "\n",
    "# Convert predicted eclipse types to integers and ensure they are within the range [0, 18]\n",
    "y_test_pred = np.clip(y_test_pred, 0, 18)\n",
    "\n",
    "# Read the true eclipse labels for the testing data\n",
    "true_labels_df = pd.read_csv(\"Eclipse_Pred\\True_Eclipse_Test_Label.csv\", index_col=\"Catalog Number\")\n",
    "\n",
    "# Map the predicted Eclipse types\n",
    "mapped_pred = np.where((y_test_pred >= 0) & (y_test_pred <= 5), 0,  # Map 0-5 to 0\n",
    "              np.where((y_test_pred >= 6) & (y_test_pred <= 11), 6,  # Map 6-11 to 6\n",
    "              np.where((y_test_pred >= 12) & (y_test_pred <= 14), 12,  # Map 12-14 to 12\n",
    "              np.where((y_test_pred >= 15) & (y_test_pred <= 18), 15, y_test_pred))))  # Map 15-18 to 15\n",
    "\n",
    "# Calculate test accuracy by comparing mapped predicted and true labels\n",
    "test_accuracy = np.mean(mapped_pred == true_labels_df[\"Eclipse Type\"]) * 100\n",
    "print(\"\\nTest Accuracy based on True Labels: {:.2f}%\".format(test_accuracy))\n",
    "\n",
    "# Write the predicted eclipse types to the DataFrame\n",
    "test_eclipse_df['Pred_Eclipse_Type'] = mapped_pred\n",
    "\n",
    "# Write the predictions to a new file\n",
    "test_eclipse_df.to_csv(\"Project3_pred.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313aa7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split Accuracy: 0.6783167018622642\n",
      "Test Split Accuracy: 0.6620003651994877\n",
      "\n",
      "Test Accuracy based on True Labels: 15.99%\n"
     ]
    }
   ],
   "source": [
    "# Model 3 Linear Regression - Mapped\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 250:\n",
    "    min_count = 250\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "\n",
    "# Drop rows with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# Drop features with no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "# Set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# Split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('lr', LinearRegression())])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'lr__fit_intercept': [True, False],  # Whether to calculate the intercept for this model\n",
    "    'lr__copy_X': [True, False],  # Whether to copy the data (True) or overwrite it (False)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(clf2, param_grid, cv=4, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for linear regression\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the new parameters to the pipeline\n",
    "clf2.set_params(**best_params)\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# output all relevant accuracies\n",
    "print(\"Train Split Accuracy:\", clf2.score(X_train, y_train))\n",
    "print(\"Test Split Accuracy:\", clf2.score(X_test, y_test)) \n",
    "\n",
    "## test the data against the testing data ##\n",
    "\n",
    "# read in the testing data\n",
    "test_eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Test_Without_Eclipse_Type.csv\", index_col = \"Catalog Number\")\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "test_eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "test_eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "test_eclipse_df = test_eclipse_df.drop([\"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "test_X = test_eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "# scale the data, then impute the data\n",
    "scaler = StandardScaler()\n",
    "test_X_scaled = scaler.fit_transform(test_X)\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan, fill_value=None)\n",
    "test_X_imputed = imputer.fit_transform(test_X_scaled)\n",
    "\n",
    "# Predict eclipse types for the testing data\n",
    "y_test_pred = clf2.predict(test_X_imputed)\n",
    "\n",
    "# Convert predicted eclipse types to integers and ensure they are within the range [0, 18]\n",
    "y_test_pred = np.clip(y_test_pred, 0, 18)\n",
    "\n",
    "# Read the true eclipse labels for the testing data\n",
    "true_labels_df = pd.read_csv(\"Eclipse_Pred\\True_Eclipse_Test_Label.csv\", index_col=\"Catalog Number\")\n",
    "\n",
    "# Map the predicted Eclipse types\n",
    "mapped_pred = np.where((y_test_pred >= 0) & (y_test_pred <= 5), 0,  # Map 0-5 to 0\n",
    "              np.where((y_test_pred >= 6) & (y_test_pred <= 11), 6,  # Map 6-11 to 6\n",
    "              np.where((y_test_pred >= 12) & (y_test_pred <= 14), 12,  # Map 12-14 to 12\n",
    "              np.where((y_test_pred >= 15) & (y_test_pred <= 18), 15, y_test_pred))))  # Map 15-18 to 15\n",
    "\n",
    "# Calculate test accuracy by comparing mapped predicted and true labels\n",
    "test_accuracy = np.mean(mapped_pred == true_labels_df[\"Eclipse Type\"]) * 100\n",
    "print(\"\\nTest Accuracy based on True Labels: {:.2f}%\".format(test_accuracy))\n",
    "\n",
    "# Write the predicted eclipse types to the DataFrame\n",
    "test_eclipse_df['Pred_Eclipse_Type'] = mapped_pred\n",
    "\n",
    "# Write the predictions to a new file\n",
    "test_eclipse_df.to_csv(\"Project3_pred.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e925f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9922222222222222\n",
      "Test Accuracy: 0.95\n",
      "[[ 93  13   0   0   1   0   0   0   1   0   2   2]\n",
      " [  0 104   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 105   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  89   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  81   0  14   0   8   2   0   0]\n",
      " [  0   0   0   0   0  93   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  90   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0  97   0   0   0   0]\n",
      " [  1   0   0   0   3   0   1   0  77   2   5   4]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 117   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  94]]\n",
      "\n",
      "Test Accuracy based on True Labels: 52.02%\n"
     ]
    }
   ],
   "source": [
    "# model 4 Support Vector Machines - Mapped\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 250:\n",
    "    min_count = 250\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "\n",
    "# Drop rows with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# Drop features with no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "# Set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# Split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "# Set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('svm', SVC())])\n",
    "\n",
    "# define the parameter grid for the classifier\n",
    "param_grid = {\n",
    "    'svm__C': [0.01, 0.1, 1],  # Reduce C for more regularization\n",
    "    'svm__kernel': ['linear'],  # Use a simpler kernel like linear\n",
    "    'svm__probability': [True],  # Enable probability estimates for better calibration\n",
    "    'svm__class_weight': [None, 'balanced']  # Try different class weights\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(clf2, param_grid, cv=3, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Apply best_estimator to the pipeline using set_params function\n",
    "clf2.set_params(**best_estimator.get_params())\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted labels and set up confustion matrix\n",
    "y_pred = clf2.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Get the training and testing accuracy\n",
    "train_accuracy = clf2.score(X_train, y_train)\n",
    "test_accuracy = clf2.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(cm)\n",
    "\n",
    "## test the data against the testing data ##\n",
    "\n",
    "# read in the testing data\n",
    "test_eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Test_Without_Eclipse_Type.csv\", index_col = \"Catalog Number\")\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "test_eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "test_eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "test_eclipse_df = test_eclipse_df.drop([\"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "test_X = test_eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "# scale the data, then impute the data\n",
    "scaler = StandardScaler()\n",
    "test_X_scaled = scaler.fit_transform(test_X)\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan, fill_value=None)\n",
    "test_X_imputed = imputer.fit_transform(test_X_scaled)\n",
    "\n",
    "# Predict eclipse types for the testing data\n",
    "y_test_pred = clf2.predict(test_X_imputed)\n",
    "\n",
    "# Convert predicted eclipse types to integers and ensure they are within the range [0, 18]\n",
    "y_test_pred = np.clip(y_test_pred, 0, 18)\n",
    "\n",
    "# Read the true eclipse labels for the testing data\n",
    "true_labels_df = pd.read_csv(\"Eclipse_Pred\\True_Eclipse_Test_Label.csv\", index_col=\"Catalog Number\")\n",
    "\n",
    "# Map the predicted Eclipse types\n",
    "mapped_pred = np.where((y_test_pred >= 0) & (y_test_pred <= 5), 0,  # Map 0-5 to 0\n",
    "              np.where((y_test_pred >= 6) & (y_test_pred <= 11), 6,  # Map 6-11 to 6\n",
    "              np.where((y_test_pred >= 12) & (y_test_pred <= 14), 12,  # Map 12-14 to 12\n",
    "              np.where((y_test_pred >= 15) & (y_test_pred <= 18), 15, y_test_pred))))  # Map 15-18 to 15\n",
    "\n",
    "# Calculate test accuracy by comparing mapped predicted and true labels\n",
    "test_accuracy = np.mean(mapped_pred == true_labels_df[\"Eclipse Type\"]) * 100\n",
    "print(\"\\nTest Accuracy based on True Labels: {:.2f}%\".format(test_accuracy))\n",
    "\n",
    "# Write the predicted eclipse types to the DataFrame\n",
    "test_eclipse_df['Pred_Eclipse_Type'] = mapped_pred\n",
    "\n",
    "# Write the predictions to a new file\n",
    "test_eclipse_df.to_csv(\"Project3_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8f0e032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9733333333333334\n",
      "Confusion Matrix:\n",
      " [[57  3  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5 39  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 52  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 41  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 48  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0 51  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 43  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 50  4  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 55  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 53  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0 55]]\n",
      "\n",
      "Test Accuracy based on True Labels: 65.19%\n"
     ]
    }
   ],
   "source": [
    "# model 5 Gradient Boosted Trees - Mapped\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# read in the .csv file\n",
    "eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Train.csv\")\n",
    "\n",
    "# get the numbers of the types of eclipses\n",
    "total_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 0]\n",
    "Tm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 1]\n",
    "Ts_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 2]\n",
    "T_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 3]\n",
    "T_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 4]\n",
    "Tn_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 5]\n",
    "annular_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 6]\n",
    "As_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 7]\n",
    "Am_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 8]\n",
    "A_plus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 9]\n",
    "A_minus_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 10]\n",
    "An_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 11]\n",
    "partial_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 12]\n",
    "Pb_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 13]\n",
    "Pe_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 14]\n",
    "hybrid_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 15]\n",
    "Hm_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 16]\n",
    "H2_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 17]\n",
    "H3_eclipse = eclipse_df[eclipse_df['Eclipse Type'] == 18]\n",
    "\n",
    "# normalize the totals for each type to reduce overfitting or other logic errors\n",
    "min_count = min(len(total_eclipse), len(annular_eclipse), len(hybrid_eclipse), len(partial_eclipse), \n",
    "                len(Tm_eclipse), len(Ts_eclipse), len(T_plus_eclipse), len(T_minus_eclipse), \n",
    "                len(Tn_eclipse), len(As_eclipse), len(Am_eclipse), len(A_plus_eclipse), \n",
    "                len(A_minus_eclipse), len(An_eclipse), len(Pb_eclipse), len(Pe_eclipse), \n",
    "                len(Hm_eclipse), len(H2_eclipse), len(H3_eclipse))\n",
    "\n",
    "if min_count < 125:\n",
    "    min_count = 125\n",
    "sample_total_eclipse = total_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tm_eclipse = Tm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Ts_eclipse = Ts_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_plus_eclipse = T_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_T_minus_eclipse = T_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Tn_eclipse = Tn_eclipse.sample(n = min_count, replace = True)\n",
    "sample_annular_eclipse = annular_eclipse.sample(n = min_count, replace = True)\n",
    "sample_As_eclipse = As_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Am_eclipse = Am_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_plus_eclipse = A_plus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_A_minus_eclipse = A_minus_eclipse.sample(n = min_count, replace = True)\n",
    "sample_An_eclipse = An_eclipse.sample(n = min_count, replace = True)\n",
    "sample_partial_eclipse = partial_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pb_eclipse = Pb_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Pe_eclipse = Pe_eclipse.sample(n = min_count, replace = True)\n",
    "sample_hybrid_eclipse = hybrid_eclipse.sample(n = min_count, replace = True)\n",
    "sample_Hm_eclipse = Hm_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H2_eclipse = H2_eclipse.sample(n = min_count, replace = True)\n",
    "sample_H3_eclipse = H3_eclipse.sample(n = min_count, replace = True)\n",
    "\n",
    "# reread the new balanced data\n",
    "eclipse_df = pd.concat([sample_total_eclipse, sample_Tm_eclipse, sample_Ts_eclipse,\n",
    "                        sample_T_plus_eclipse, sample_T_minus_eclipse, sample_Tn_eclipse,\n",
    "                        sample_annular_eclipse, sample_As_eclipse, sample_Am_eclipse,\n",
    "                        sample_A_plus_eclipse, sample_A_minus_eclipse, sample_An_eclipse,\n",
    "                        sample_partial_eclipse, sample_Pb_eclipse, sample_Pe_eclipse, \n",
    "                        sample_hybrid_eclipse, sample_Hm_eclipse, sample_H2_eclipse,\n",
    "                        sample_H3_eclipse], ignore_index = True)\n",
    "\n",
    "\n",
    "# Drop rows with missing data in \"Central Duration Seconds\"\n",
    "eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# Drop features with no or negative impact on results\n",
    "eclipse_df = eclipse_df.drop([\"Catalog Number\", \"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "# Set the X (features) and Y (target variables)\n",
    "X = eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "y = eclipse_df['Eclipse Type']\n",
    "\n",
    "# Split the data between training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "# Set up the pipeline for use by the param_grid\n",
    "clf2 = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"mean\", missing_values = np.nan, fill_value = None)),\n",
    "                       ('scaler', StandardScaler()),\n",
    "                       ('gradient_boosting', GradientBoostingClassifier())])\n",
    "\n",
    "# define the parameter grid for the classifier\n",
    "param_grid = {\n",
    "    'gradient_boosting__max_depth': [3, 5, 7],  # Maximum depth of the individual trees\n",
    "    'gradient_boosting__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'gradient_boosting__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'gradient_boosting__n_estimators': [50, 100, 200],  # Number of boosting stages to be run\n",
    "    'gradient_boosting__learning_rate': [0.05, 0.1, 0.2]  # Step size shrinkage used in update to prevent overfitting\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(clf2, param_grid, cv=3, scoring='accuracy', verbose = 0, n_jobs = -1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Apply best_estimator to the pipeline using set_params function\n",
    "clf2.set_params(**best_estimator.get_params())\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "# Get the training and testing accuracy\n",
    "train_accuracy = clf2.score(X_train, y_train)\n",
    "test_accuracy = clf2.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "## test the data against the testing data ##\n",
    "\n",
    "# read in the testing data\n",
    "test_eclipse_df = pd.read_csv(\"Eclipse_Pred\\Eclipse_Test_Without_Eclipse_Type.csv\", index_col = \"Catalog Number\")\n",
    "\n",
    "# Drop columns with missing data in \"Central Duration Seconds\"\n",
    "test_eclipse_df.dropna(subset=['Central Duration Seconds'], inplace=True)\n",
    "\n",
    "# Replace non-numeric values in the DataFrame with NaN\n",
    "test_eclipse_df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# drop all features that have no or negative impact on results\n",
    "test_eclipse_df = test_eclipse_df.drop([\"Calendar Date\", \"Eclipse Time\", \"Latitude\",\n",
    "                              \"Longitude\", \"Central Duration\", \"Date Time\", \"Visibility\",\n",
    "                              \"Geographical Hemisphere\", \"Daytime/Nighttime\", \"Sun Constellation\",\n",
    "                              \"Eclipse Classification\", \"Duration in Seconds\", \"Year Modulus\",\n",
    "                              \"Decade\", \"ESC Moving Average\", \"ESC Wide-Scale Moving Average\",\n",
    "                              \"Cluster\", \"Cluster 6\"], axis=1)\n",
    "\n",
    "\n",
    "# set the X (features) and Y (target variables)\n",
    "test_X = test_eclipse_df[[\"Delta T (s)\", \"Lunation Number\", \"Saros Number\", \"Gamma\",\n",
    "               \"Eclipse Magnitude\", \"Sun Altitude\", \"Sun Azimuth\", \"Path Width (km)\",\n",
    "               \"Year\", \"Month\", \"Day\", \"Eclipse Latitude\", \"Eclipse Longitude\",\n",
    "               \"obliquity\", \"Inter-Eclipse Duration\", \"Visibility Score\",\n",
    "               \"Moon Distance (km)\", \"Sun Distance (km)\", \"Moon Angular Diameter (degrees)\",\n",
    "               \"Sun Angular Diameter (degrees)\", \"Central Duration Seconds\",\n",
    "               \"Normalized Duration\", \"Normalized Path Width\", \"EII\", \"HEAS\",\n",
    "               \"Localized ESC\", \"Eclipse Interval\"]]\n",
    "\n",
    "# scale the data, then impute the data\n",
    "scaler = StandardScaler()\n",
    "test_X_scaled = scaler.fit_transform(test_X)\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan, fill_value=None)\n",
    "test_X_imputed = imputer.fit_transform(test_X_scaled)\n",
    "\n",
    "# Predict eclipse types for the testing data\n",
    "y_test_pred = clf2.predict(test_X_imputed)\n",
    "\n",
    "# Convert predicted eclipse types to integers and ensure they are within the range [0, 18]\n",
    "y_test_pred = np.clip(y_test_pred, 0, 18)\n",
    "\n",
    "# Read the true eclipse labels for the testing data\n",
    "true_labels_df = pd.read_csv(\"Eclipse_Pred\\True_Eclipse_Test_Label.csv\", index_col=\"Catalog Number\")\n",
    "\n",
    "# Map the predicted Eclipse types\n",
    "mapped_pred = np.where((y_test_pred >= 0) & (y_test_pred <= 5), 0,  # Map 0-5 to 0\n",
    "              np.where((y_test_pred >= 6) & (y_test_pred <= 11), 6,  # Map 6-11 to 6\n",
    "              np.where((y_test_pred >= 12) & (y_test_pred <= 14), 12,  # Map 12-14 to 12\n",
    "              np.where((y_test_pred >= 15) & (y_test_pred <= 18), 15, y_test_pred))))  # Map 15-18 to 15\n",
    "\n",
    "# Calculate test accuracy by comparing mapped predicted and true labels\n",
    "test_accuracy = np.mean(mapped_pred == true_labels_df[\"Eclipse Type\"]) * 100\n",
    "print(\"\\nTest Accuracy based on True Labels: {:.2f}%\".format(test_accuracy))\n",
    "\n",
    "# Write the predicted eclipse types to the DataFrame\n",
    "test_eclipse_df['Pred_Eclipse_Type'] = mapped_pred\n",
    "\n",
    "# Write the predictions to a new file\n",
    "test_eclipse_df.to_csv(\"Project3_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 6 K means - Mapped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
